{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33eceaa7-456c-430d-86ee-f630b7555f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bbd5140-742e-416a-a847-bd940cf24018",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./test_images/1.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('./test_images/1.png')\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b566a602-0961-4f3c-a913-5bbda7f06d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75f6e51-1587-4f98-9b0a-bbbadda0b885",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57104815-2e4f-4a13-a527-b06209673c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a1feb8-9ec5-4356-9d94-c935d9f99f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(gray, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f912fe-abe1-4398-9636-8e42ae20dc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('./opencv/haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('./opencv/haarcascades/haarcascade_eye.xml')\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308220ee-6425-46f8-ba34-fa2ab21fc14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x,y,w,h) = faces[0]\n",
    "x,y,w,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780fa2d8-a57a-4ae2-a7cb-617654fd1c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "plt.imshow(face_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc090adc-07b0-4081-9a25-a2e4b1cef236",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n",
    "for (x,y,w,h) in faces:\n",
    "    face_img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = face_img[y:y+h, x:x+w]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "        \n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(face_img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5664526b-f8b1-44ae-b8a7-e415f9ad51bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(roi_color, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1f577f-af41-414a-9fd4-ed651ea45fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_img = np.array(roi_color)\n",
    "cropped_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ead9999-fb5a-43d4-b7f9-4e88a84cb8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "import cv2    \n",
    "\n",
    "def w2d(img, mode='haar', level=1):\n",
    "    imArray = img\n",
    "    #Datatype conversions\n",
    "    #convert to grayscale\n",
    "    imArray = cv2.cvtColor( imArray,cv2.COLOR_RGB2GRAY )\n",
    "    #convert to float\n",
    "    imArray =  np.float32(imArray)   \n",
    "    imArray /= 255;\n",
    "    # compute coefficients \n",
    "    coeffs=pywt.wavedec2(imArray, mode, level=level)\n",
    "\n",
    "    #Process Coefficients\n",
    "    coeffs_H=list(coeffs)  \n",
    "    coeffs_H[0] *= 0;  \n",
    "\n",
    "    # reconstruction\n",
    "    imArray_H=pywt.waverec2(coeffs_H, mode);\n",
    "    imArray_H *= 255;\n",
    "    imArray_H =  np.uint8(imArray_H)\n",
    "\n",
    "    return imArray_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700ecab3-5faa-423e-8f92-5881be64ee68",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_har = w2d(cropped_img,'db1',5)\n",
    "plt.imshow(im_har, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9bb420-3ef1-440c-bad7-4851f7b42932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cropped_image_if_2_eyes(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        if len(eyes) >= 2:\n",
    "            return roi_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c07b967-569c-4062-9fef-faf83fcb2244",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image = cv2.imread('./test/1.png')\n",
    "plt.imshow(original_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f0e5cf-44d6-4ae5-8a3c-e811c3c20711",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image = get_cropped_image_if_2_eyes('./test/1.png')\n",
    "plt.imshow(cropped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712c780c-b3b3-42cb-92da-e3866f902eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_image_obstructed = cv2.imread('./test/2.png')\n",
    "plt.imshow(org_image_obstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9725fc1-832d-4a61-ad49-ccad105639ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image_no_2_eyes = get_cropped_image_if_2_eyes('./test/2.png')\n",
    "cropped_image_no_2_eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec6e994-1811-45ae-91cc-def463a11720",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"./dataset/\"\n",
    "path_to_cr_data = \"./dataset/cropped/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c65722-b5ca-4b09-af05-612576174679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "img_dirs = []\n",
    "for entry in os.scandir(path_to_data):\n",
    "    if entry.is_dir():\n",
    "        img_dirs.append(entry.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3790df8a-c50e-480a-a7f7-f90b570e0a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e937e7ab-5966-44cb-be35-00befa9e9270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "if os.path.exists(path_to_cr_data):\n",
    "     shutil.rmtree(path_to_cr_data)\n",
    "os.mkdir(path_to_cr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8590081-4a59-48c5-8091-fe4251b5810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image_dirs = []\n",
    "celebrity_file_names_dict = {}\n",
    "for img_dir in img_dirs:\n",
    "    count = 1\n",
    "    celebrity_name = img_dir.split('/')[-1]\n",
    "    celebrity_file_names_dict[celebrity_name] = []\n",
    "    for entry in os.scandir(img_dir):\n",
    "        roi_color = get_cropped_image_if_2_eyes(entry.path)\n",
    "        if roi_color is not None:\n",
    "            cropped_folder = path_to_cr_data + celebrity_name\n",
    "            if not os.path.exists(cropped_folder):\n",
    "                os.makedirs(cropped_folder)\n",
    "                cropped_image_dirs.append(cropped_folder)\n",
    "                print(\"Generating cropped images in folder: \",cropped_folder)\n",
    "            cropped_file_name = celebrity_name + str(count) + \".png\"\n",
    "            cropped_file_path = cropped_folder + \"/\" + cropped_file_name\n",
    "            cv2.imwrite(cropped_file_path, roi_color)\n",
    "            celebrity_file_names_dict[celebrity_name].append(cropped_file_path)\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151c8f7e-e767-4d74-bdc3-7af52149afc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "celebrity_file_names_dict = {}\n",
    "for img_dir in cropped_image_dirs:\n",
    "    celebrity_name = img_dir.split('/')[-1]\n",
    "    file_list = []\n",
    "    for entry in os.scandir(img_dir):\n",
    "        file_list.append(entry.path)\n",
    "    celebrity_file_names_dict[celebrity_name] = file_list\n",
    "celebrity_file_names_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977582ec-2895-461e-8fba-ed51dfdeeb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {}\n",
    "count = 0\n",
    "for celebrity_name in celebrity_file_names_dict.keys():\n",
    "    class_dict[celebrity_name] = count\n",
    "    count = count + 1\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2861b21-f640-46c1-96fc-bd897fe0ca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "for celebrity_name, training_files in celebrity_file_names_dict.items():\n",
    "    for training_image in training_files:\n",
    "        img = cv2.imread(training_image)\n",
    "        scalled_raw_img = cv2.resize(img, (32, 32))\n",
    "        img_har = w2d(img,'db1',5)\n",
    "        scalled_img_har = cv2.resize(img_har, (32, 32))\n",
    "        combined_img = np.vstack((scalled_raw_img.reshape(32*32*3,1),scalled_img_har.reshape(32*32,1)))\n",
    "        X.append(combined_img)\n",
    "        y.append(class_dict[celebrity_name]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99078d8-0760-42f1-9a7d-7295fa07a30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c24bf73-3991-4c60-aa54-928b54bd6202",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b618e906-4783-4369-a840-e8d12867c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362ecd5b-f6a9-4482-8e05-e543ba6c604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(len(X),4096).astype(float)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45149f5-d70f-4d84-a4c5-40f8e3950a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2394eaba-0346-4385-9cac-7d9e1c449235",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC(kernel = 'rbf', C = 10))])\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1a087f-19af-4279-a941-a32122389527",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pipe.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2381a8a4-4080-4f0c-97f3-7ace5be9ba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ab9907-6237-4bc9-95e8-1ceaadb8972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'svm': {\n",
    "        'model': svm.SVC(gamma='auto',probability=True),\n",
    "        'params' : {\n",
    "            'svc__C': [1,10,100,1000],\n",
    "            'svc__kernel': ['rbf','linear']\n",
    "        }  \n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'randomforestclassifier__n_estimators': [1,5,10]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n",
    "        'params': {\n",
    "            'logisticregression__C': [1,5,10]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d190e4b2-e56b-48ed-933c-b0c45975d480",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "best_estimators = {}\n",
    "import pandas as pd\n",
    "for algo, mp in model_params.items():\n",
    "    pipe = make_pipeline(StandardScaler(), mp['model'])\n",
    "    clf =  GridSearchCV(pipe, mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores.append({\n",
    "        'model': algo,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "    best_estimators[algo] = clf.best_estimator_\n",
    "    \n",
    "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296d99e8-3d6e-4d84-9a90-adf4ddd60d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbc6aa8-c25c-43f7-bac7-fed071d91673",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimators['svm'].score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba37e6c4-b3c8-4eee-8ddb-5f2794dca810",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimators['random_forest'].score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5036a6-3795-4051-ad6e-4de223bf0ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimators['logistic_regression'].score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c197280d-094d-4a5b-bc15-d5ba967b1a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf = best_estimators['svm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4458ede-40f4-4682-a9fb-9fcbdaa18116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, best_clf.predict(X_test))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129e4b18-6c29-404b-b5de-6a6c1057a0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c02ffc7-9197-48b8-9618-0c59f74043b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a722f4-0599-4a0d-b157-382ecfa7120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install joblib\n",
    "import joblib \n",
    "# Save the model as a pickle in a file \n",
    "joblib.dump(best_clf, 'saved_model.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f4ada7-12be-4267-bee4-296b8397e96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"class_dictionary.json\",\"w\") as f:\n",
    "    f.write(json.dumps(class_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f1a56a-fd63-41c3-9763-4201eb6453b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
